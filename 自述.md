# 百日机器学习代码挑战

油管网红 [Siraj Raval] 发起的100天机器学习代码挑战 (https://github.com/llSourcell)

可以在这找到代码 [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/tree/master/datasets)

## 数据预处理 | 第一天
可以在这找到代码[here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%201_Data%20PreProcessing.md).

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%201.jpg">
</p>

## 简单线性回归 | 第二天
Check out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day2_Simple_Linear_Regression.md).

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%202.jpg">
</p>

## 多元线性回归 | 第三天
Check out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day3_Multiple_Linear_Regression.md).

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%203.jpg">
</p>

## 逻辑回归 | 第四天

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%204.jpg">
</p>

## 逻辑回归 | 第五天
Moving forward into #100DaysOfMLCode today I dived into the deeper depth of what actually Logistic Regression is and what is the math involved behind it. Learned how cost function is calculated and then how to apply gradient descent algorithm to cost function to minimize the error in prediction.  
Due to less time I will now be posting a infographic on alternate days.
Also if someone wants to help me out in documentaion of code and has already some experince in the field and knows Markdown for github please contact me on LinkedIn :) .

## 逻辑回归的应用 | 第六天
Check out the Code [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%206%20Logistic%20Regression.md)

## K最近邻分类算法 | 第七天
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%207.jpg">
</p>

## 逻辑回归背后的数学原理 | 第八天

#100DaysOfMLCode To clear my insights on logistic regression I was searching on the internet for some resource or article and I came across this article (https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) by Saishruthi Swaminathan. 

It gives a detailed description of Logistic Regression. Do check it out.

## 支持向量机 | 第九天
Got an intution on what SVM is and how it is used to solve Classification problem.

## 支持向量机 和 K最近邻分类算法 | 第十天
Learned more about how SVM works and implementing the knn algorithm.

## K最近邻分类算法的应用 | 第十一天

Implemented the K-NN algorithm for classification. #100DaysOfMLCode 
Support Vector Machine Infographic is halfway complete will update it tomorrow.

## 支持向量机 | 第十二天
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2012.jpg">
</p>

## 朴素贝叶斯分类器 | 第十三天

Continuing with #100DaysOfMLCode today I went through the Naive Bayes classifier.
I am also implementing the SVM in python using scikit-learn. Will update the code soon.

## 支持向量机的使用 | 第十四天
Today I implemented SVM on linearly related data. Used Scikit-Learn library. In scikit-learn we have SVC classifier which we use to achieve this task. Will be using kernel-trick on next implementation.
Check the code [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2013%20SVM.md).

## 朴素贝叶斯分类器 和 黑盒机器学习 | 第十五天
Learned about diffrent types of naive bayes classifer also started the lectures by [Bloomberg](https://bloomberg.github.io/foml/#home). first one in the playlist was Black Box Machine Learning. It gave the whole over view about prediction functions, feature extraction, learning algorithms, performance evaluation, cross-validation, sample bias, nonstationarity, overfitting, and hyperparameter tuning.

## 支持向量机的应用及内核技巧 | 第十六天
Using Scikit-Learn library implemented SVM algorithm along with kernel function which maps our data points into higher dimension to find optimal hyperplane. 

## 在 Coursera 上学习深度学习 | 第十七天
Completed the whole Week 1 and Week 2 on a single day. Learned Logistic regression as Neural Network. 

## 在 Coursera 上学习深度学习 第一节课 | 第十八天
Completed the Course 1 of the deep learning specialization. Implemented a neural net in python.

## 机器学习课程 , Yaser Abu-Mostafa 教授 | 第十九天
Started Lecture 1 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. It was basically an intoduction to the upcoming lectures. He also explained Perceptron Algorithm.

## 在 Coursera 上学习深度学习 第二节课  | 第二十天
Completed the Week 1 of Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.

## 网页爬虫 | 第二十一天
Watched some tutorials on how to do web scaping using Beautiful Soup in order to collect data for building a model.

## （机器学习课程）Is Learning Feasible? | 第二十二天
Lecture 2 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. Learned about Hoeffding Inequality.

## 决策树 | 第二十三天
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2023.jpg">
</p>

## （机器学习课程）Introduction To Statistical Learning Theory | 第二十四天
Lec 3 of Bloomberg ML course introduced some of the core concepts like input space, action space, outcome space, prediction functions, loss functions, and hypothesis spaces.

## 决策树的应用 | 第二十五天
Check the code [here.](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2025%20Decision%20Tree.md)
